# Pandas Cookbook

### 불리언 인덱싱

* 데이터셋으로 부터 데이터 필터링 하는 것은 가장 흔하고 기본적인 연산이라고 할 수 있습니다. 
* 불리언 인덱싱을 사용해서 데이터를 필터링 하는 것은  다양한 방법이 존재하는데, pandas에서는  불리언 값을 사용해서 행을 선택하는 방법을 의미합니다. 



#### 불리언 통계량 계산 

* 이 방법에서는 데이터 열의 조건을 적용하여 불리언 Series를 생성하여 요약 통계량을 계산하는 방법을 알아봅니다. 

  ```python
  import pandas as pd
  import numpy as np
  import matplotlib.pyplot as plt
  
  %matplotlib inline
  pd.options.display.max_columns = 50
  
  movie = pd.read_csv('data/movie.csv', index_col='movie_title')
  movie.head()
  ```

* 영화 데이터 셋을 읽고 영화 제목으로 인덱스를 구합니다. 

  ````python
  movie_2_hours = movie['duration'] > 120
  movie_2_hours.head(10)
  
  movie_2_hours.sum()
  movie_2_hours.mean()
  movie_2_hours.describe()
  movie['duration'].dropna().gt(120).mean()
  ````

* '크거나 같다' 비교 연산자를 사용해서 영화 상영시간잉 두 시간을 넘는지 확인합니다. 

* 이후 두 시간 이상인 영화 개수를 Series를 사용하여 확인합니다. 

* 두 시간 이상인 비율을 알아보기 위해서 mean 메서드를 사용합니다. 

* 이때 duration 열에는 몇개의 누락값이 존재하기 때문에 평균을 구하기 위해서는 누락값을 제거해야 합니다,. 따라서 누락값을 제거하고 조건을 적용한 다음에 평균을 계산합니다. 

  ```python
  movie_2_hours.describe()
  ```

* describe 메서드를 사용하여 Series의 요약 통계량을 확인할 수 있습니다. 

* 영화 데이터 셋에서는 불리언 값이 존재하지 않으므로 비교 연산자를 통해서 불리언 연산을 수행했습니다. 

* 단, duration 열에 누락된 값이 있음에도 불구하고, 불리언 조건은 False로 가정하고 연산을 진행했기 때문에 누락값을 삭제하면 정확한 통계량을 얻을 수 없다는 단점이 존재합니다. 



#### 다중 불리언 조건 구축 

* 파이썬에서 불리언 표현은 내장 논리 연산자인 and, or, not을 사용하지만 이 키워드는 pandas에서는 동작하지 않으므로 &, |, ~로 대체되며, 각 표현은 괄호로 묶어야 합니다. 

* 데이터셋을 위한 정교한 필터를 구축하기 위해서 복수 개의 불리언 표현을 한번에 통합하여 정확한 부분을 추출할 수 있습니다. 

  ```python
  movie = pd.read_csv('data/movie.csv', index_col='movie_title')
  movie.head()
  
  criteria1 = movie.imdb_score > 8
  criteria2 = movie.content_rating == 'PG-13'
  criteria3 = (movie.title_year < 2000) | (movie.title_year >= 2010)
  criteria2.head()
  
  criteria_final = criteria1 & criteria2 & criteria3
  criteria_final.head()
  ```

* 영화 데이터 셋을 읽고 영화 제목을 인덱스로 설정하였습니다. 

* 각 조건을 각각의 불리언 Series로 저장할 변수를 생성하였고 모든 기준을 통합하여 단일 불리언 Series에 저장하였습니다. 



#### 정렬된 고유 인덱스를 사용한 선택 

* 인덱스의 선택의 성능은 인덱스가 고유하거나 정렬되어 있을때 아주 빨라진다는 특징을 가지고 있스빈다. 

* 중복이 포함되어 있고, 정렬되지 않은 인덱스를 사용하면 성능이 떨어집니다. 

* 대학 데이터 셋을 사용하여 고유하고 정렬된 인덱스로 만들엇거 인덱스의 성능을 향상시키는 방법을 알아봅니다. 

  ```python
  college = pd.read_csv('data/college.csv')
  college2 = college.set_index('STABBR')
  college2.index.is_monotonic
  ```

* STABBR을 인덱스로 하는 별도의 DataFrame을 생성하고 인덱스가 정렬되어 있는지 확인합니다. 

  ```python
  college3 = college2.sort_index()
  college3.index.is_monotonic
  ```

* college2로부터 인덱스를 정렬해 또 다른 객체에 저장합니다. 

  ```python
  %timeit college[college['STABBR'] == 'TX']
  %timeit college2.loc['TX']
  %timeit college3.loc['TX']
  ```

* 세 가지 DataFrame에서 텍사스주를 선택하는 시간을 측정합니다. 

* 위의 비교를 통해서 정렬된 인덱스의 성능은 불리안 선택에 비해 비약적으로 향상된 것을 확인할 수 있습니다. 

* 다음은 고유한 인덱스의 경우를 살펴보기로 하겠습니다. 

  ```python
  college_unique = college.set_index('INSTNM')
  college_unique.index.is_unique
  
  college[college['INSTNM'] == 'Stanford University']
  ```

* 스탠퍼드 대학을 불리언 인덱싱으로 선택했습니다. 

  ```python
  college_unique.loc['Stanford University']
  ```

* 인덱스 선택을 통해서 대학을 선택합니다. 

* 위 둘다 동일한 데이터를 생산하지만 서로 다른 객체이며, 각각 방식의 시간을 측정합니다. 

  ```python
  %timeit college[college['INSTNM'] == 'Stanford University']
  %timeit college_unique.loc['Stanford University']
  ```

* college2 처럼 인덱스가 정렬돼 있지 않고 중복이 있는 경우 pandas는 정확한 선택을 위해 모든 인덱스를 검사해야 합니다. 

* 인덱스가 college3의 경우처럼 정렬돼 있다면 pandas는 이진 탐색 알고리즘을 활용해서 성능을 크게 향상시킬 수 있습니다.  

* 추가적으로 불리언 선택은 인덱스 선택에 비해 훨씬 유연합니다. 

* 숫자로 된 임의의 개수의 열에 대해 조건을 줄 수 있기 때문입니다. 다음 코드에서는 인덱스를 도시와 주 열을 이어 붙여서 사용합니다. 

  ```python
  college.index = college['CITY'] + ', ' + college['STABBR']
  college = college.sort_index()
  college.head()
  ```

* 여기서부터는 불리언 인덱싱 없이도 특정 도시와 주의 조합을 통해 모든 학교를 선택할 수 있다. 

  * (플로리다 마이에미 대학 선택)

  ```python
  college.loc['Miami, FL'].head()
  ```

* 이 복합 인덱스 선택을 불리언 인덱싱과 비교합니다. 속도차이가 지수 배 이상으로 차이가 나는 것을 확인할 수 있습니다. 

  ```python
  %%timeit 
  crit1 = college['CITY'] == 'Miami' 
  crit2 = college['STABBR'] == 'FL'
  college[crit1 & crit2]
  
  %timeit college.loc['Miami, FL']
  
  college[(college['CITY'] == 'Miami') & (college['STABBR'] == 'FL')].equals(college.loc['Miami, FL'])
  ```


#### 주가 전망 

* 불리언 인덱싱을 사용해서 특정 주식이 어던 특정값을 상향하거나 하향한 기간을 모두 찾을 수 있습니다. 

* 여기서는 슐룸베르거 주식을 2010년 부터 2017년 중반까지 조사하고, 불리언 인덱싱을 사용해서 종가 기준으로 해당 기간의 하위 10%와 상위 10% 지점만 부각시켜 보도록 하겠습니다. 

  ```python
  slb = pd.read_csv('data/slb_stock.csv', index_col='Date', parse_dates=['Date'])
  slb.head()
  
  slb_close = slb['Close']
  slb_summary = slb_close.describe(percentiles=[.1, .9])
  slb_summary
  
  upper_10 = slb_summary.loc['90%']
  lower_10 = slb_summary.loc['10%']
  criteria = (slb_close < lower_10) | (slb_close > upper_10)
  slb_top_bottom_10 = slb_close[criteria]
  
  slb_close.plot(color='black', figsize=(12,6))
  slb_top_bottom_10.plot(marker='o', style=' ', ms=4, color='lightgray')
  
  xmin = criteria.index[0]
  xmax = criteria.index[-1]
  plt.hlines(y=[lower_10, upper_10], xmin=xmin, xmax=xmax,color='black')
  ```

* 종가를 Series로 선택하고 describe 메서드를 사용하여 Series의 요약 통계량을 살펴봅니다. 

* 불리언 선택을 사용해서 모든 종가 중 하위 10%와 상위 10%를 선택합니다. 

* 모든 종가를 검은 그래프로 그리고,  그 위에 필터링이 끝난 Series를 밝은 회색으로 그리고, matplotlib 라이브러리를 사용하여 하위, 상위 해당 10% 지점에 수평선을 표시합니다. 

* fill_between 함수를 사용하며 두 선 사이의 모든 영역을 칠할 수 있습니다. 이 함수의 where라는 매개변수에 불리언 Series를 지정하면 어느 영역을 칠할 것인지 정확히 선택할 수 있습니다. 

  ```python
  slb_close.plot(color='black', figsize=(12,6))
  plt.hlines(y=[lower_10, upper_10], 
             xmin=xmin, xmax=xmax,color='lightgray')
  plt.fill_between(x=criteria.index, y1=lower_10,
                   y2=slb_close.values, color='black')
  plt.fill_between(x=criteria.index,y1=lower_10,
                   y2=slb_close.values, where=slb_close < lower_10,
                   color='lightgray')
  plt.fill_between(x=criteria.index, y1=upper_10, 
                   y2=slb_close.values, where=slb_close > upper_10,
                   color='lightgray')
  ```



#### SQL WHERE 절 해석 

* pandas에는 데이터베이스에 연결해 SQL 명령문을 전송하는 기능이 있습니다. 

* SQL SELECT 명령분 내에 WHERE 데이터를 필터링 하는 것은 매우 보편적인 일입니다. 

* 이번에는 직원 데이터셋에서 특정 부분 집합을 선택하는 것으로 SQL과 동일한 효과를 나타내는 pandas 코드를 작성합니다. 

  ```python
  employee = pd.read_csv('data/employee.csv')
  employee.DEPARTMENT.value_counts().head()
  employee.GENDER.value_counts()
  employee.BASE_SALARY.describe().astype(int)
  ```


* employee 데이터셋을 DataFrame으로 읽어옵니다. 

* 데이터를 필터링 하기전에 필터에 사용될 정확한 값을 알기 위해 필터링 된 각 열에 대해 수작업으로 살펴봅니다. 

  ```python
  depts = ['Houston Police Department-HPD', 
               'Houston Fire Department (HFD)']
  criteria_dept = employee.DEPARTMENT.isin(depts)
  criteria_gender = employee.GENDER == 'Female'
  criteria_sal = (employee.BASE_SALARY >= 80000) & \
                 (employee.BASE_SALARY <= 120000)
  ```

* 각 기준에 대해 하나씩 단일 문장을 작성하고, isin 메서드를 사용해 여러 값 중에 일치하는 값이 있는지 확인합니다. 

  ```python
  criteria_final = criteria_dept & criteria_gender & criteria_sal
  
  select_columns = ['UNIQUE_ID', 'DEPARTMENT', 'GENDER', 'BASE_SALARY']
  employee.loc[criteria_final, select_columns].head()
  ```

* 모든 불리언 Series를 합치고 불리언 인덱싱을 통해서 최종 조건을 만족하는 열들만 선택합니다. 

* 필터링 하기 전에 분명 사용해야 할 정확한 문자열을 알소고 있어야 합니다. 

* Series의 value_counts 메서드는 정확한 문자열 이름과 그 값의 빈도수를 동시에 알아낼 수 있는 도구 입니다. 

* Series의 isin 메서드는 SQL IN 연산자와 동일하고 유지하고자 하는 모든 값을 리스트로 입력받습니다. 

* 급여 조건에 관한 불리언 Series인 criteria_sal는 간단한 2개의 부등식을 병합하여 단일 불리언 Series를 필터로 생성합니다. 

* pandas에는 많은 연산에서 동일한 결과를 얻을 수 있는 여러가지 방법이 존재하는데 이번에는 SQL과 비슷하게 between 메서드를 통해서 동일한 급여조건을 선택할 수 있습니다. 

  ```python
  criteria_sal = employee.BASE_SALARY.between(80000, 120000)
  
  top_5_depts = employee.DEPARTMENT.value_counts().index[:5]
  criteria = ~employee.DEPARTMENT.isin(top_5_depts)
  employee[criteria].head()
  ```

* isin의 또 다른 용도는 pandas 문장에서 생성된 일련의 값을 자동으로 제공하는 것입니다.

* 이 방법은 리스트에서 저장된 문자열을 수작업으로 검사해야 하는 수고를 덜 수 있는데 반대로 가장 빈전이 나타나는 부서 중 상위 5개의 속하는 모든 행을 제외시켜보도록 합니다.  

#### 주식 시장 수익률의 정규성 검정 

* 주식 시장의 수익률은 정규분포처럼 보이지만 사실은 그렇지 않은 대표적인 예입니다. 

* 아마존의 일별 주식 시장 수익률을 알아보고 정규 분포를 따르는지 검증합니다. 

* 아마존 주가 데이터를 읽고 날자를 인덱스로 설정합니다. 

  ```python
  amzn = pd.read_csv('data/amzn_stock.csv', index_col='Date', parse_dates=['Date'])
  amzn.head()
  ```

* 종가만 선택하여 Series를 생성하고 pct_change 메서드를 사용해 일별 수익률을 계산합니다. 

  ```python
  amzn_daily_return = amzn.Close.pct_change()
  amzn_daily_return.head()
  ```

* 누락값을 삭제하고 수익률의 히스토그램을 그리고 분포를 시각적으로 살펴봅니다. 

  ```python
  amzn_daily_return = amzn_daily_return.dropna()
  amzn_daily_return.hist(bins=20)
  ```

* 정규 분포는 68-95-99.7법칙을 따른다. 즉 68%의 데이터는 1표준편차, 95%는 2표준편차, 99.7%는 3 표준편차에 분포한다는 뜻으로 일별 수익률 중 평균으로 부터 1, 2, 3 표준편차 내의 범위에 속하는 비율을 다음과 같이 계산합니다.

  ```python
  mean = amzn_daily_return.mean()  
  std = amzn_daily_return.std()
  
  abs_z_score = amzn_daily_return.sub(mean).abs().div(std)
  
  pcts = [abs_z_score.lt(i).mean() for i in range(1,4)]
  print('{:.3f} fall within 1 standard deviation. '
        '{:.3f} within 2 and {:.3f} within 3'.format(*pcts))
  ```

* 각 관측값 z_score의 절대 값을 계산합니다. 

  *  z_score는 평균으로 부터 얼마 정도의 표준편차만큼 떨어져 있는지의 수치입니다. 

* 표준편차로부터 1, 2, 3 거리인 비율을 살펴봅니다. 

* 비율은 규칙 1과 3에 있어서 많이 벗어나기 때문에 아마존의 일별 주식 수익률은 정규 분포를 따르지 않는다는 결론을 내릴 수 있습니다. 

* 추가적으로 이 프로세스를 자동화 하기 위해서 주가 데이터를 읽어드리고 일별 데이터를 평균으로부터 1, 2, 3 표준편차 범위에 대한 비율에 따라 일변 수익률 히스토그램을 그리도록 할 수 있습니다. 

  ```python
  def test_return_normality(stock_data):
      close = stock_data['Close']
      daily_return = close.pct_change().dropna()
      daily_return.hist(bins=20)
      mean = daily_return.mean() 
      std = daily_return.std()
      
      abs_z_score = abs(daily_return - mean) / std
      pcts = [abs_z_score.lt(i).mean() for i in range(1,4)]
  
      print('{:.3f} fall within 1 standard deviation. '
            '{:.3f} within 2 and {:.3f} within 3'.format(*pcts))
            
  slb = pd.read_csv('data/slb_stock.csv', 
                    index_col='Date', parse_dates=['Date'])
  test_return_normality(slb)   
  ```

#### query 메서드를 사용한 불리언 인덱싱의 가독성 개선 

* 불리언 인덱싱이 데이터를 읽고 쓰는데 있어 최선의 선택은 아닙니다. 특히 복잡한 필터를 한 줄로 사용하는 경우에 더욱 두드러집니다. 

* pandas에는 DataFrame의 query 메서드를 사용해 문자열 기반의 문법을 제공하고 있는데, 이를 사용하면 보다 명확한 표현이 가능합니다. 

* 방금전에 했던 SQL WHERE 절 해석을 복제하여 사용하나, Dataframe의 query 메서드의 장점을 활용해서 사용합니다. 

  ```python
  employee = pd.read_csv('data/employee.csv')
  depts = ['Houston Police Department-HPD', 'Houston Fire Department (HFD)']
  select_columns = ['UNIQUE_ID', 'DEPARTMENT', 'GENDER', 'BASE_SALARY']
  
  qs = "DEPARTMENT in @depts " \
           "and GENDER == 'Female' " \
           "and 80000 <= BASE_SALARY <= 120000"
          
  emp_filtered = employee.query(qs)
  emp_filtered[select_columns].head()
  ```

* 직원 데이터를 읽고 선택한 부서를 지정하고 열을 변수에 임포트 합니다.

* query 문자열을 구성하고 메서드를 실행합니다. 

* query 메서드에 사용하는 문자열은 pandas 코드에 비해 훨씬 일상 영어에 가깝다고 할 수 있습니다. 

* 모든 Dataframe의 열 이름은 query의 namespace내에서 작은 따옴표 없이 간단히 참고 할 수 있으며, Female처럼 문자열을 사용하려면 작은 따옴표로 감싸야 합니다. 

* query 구문은 이중 부등식을 하나의 식으로 표현할 수 있습니다. 

* 부서 이름을 수작업으로 일일이 입력하는 대신 다음과 같이 프로그램으로 생성하여 사용할 수 있습니다. 

  * 빈도수 10위에 드는 부서에 속하지 않는 모든 여직원

  ```python
  top10_depts = employee.DEPARTMENT.value_counts().index[:10].tolist()
  qs = "DEPARTMENT not in @top10_depts and GENDER == 'Female'"
  employee_filtered2 = employee.query(qs)
  employee_filtered2[['DEPARTMENT', 'GENDER']].head()
  ```



#### where 메서드를 사용한 Series 보존 

* where 메서드를 사용하면 모든 값을 제거하지 않고 유지할 수 있습니다. where 메서드는 Series나 Dataframe을 원래 크기대로 유지하며 조건에 맞지 않는 값은 누락값으로 설정하거나 다른 것으로 대체 할 수 있습니다. 

  ```python
  movie = pd.read_csv('data/movie.csv', index_col='movie_title')
  fb_likes = movie['actor_1_facebook_likes'].dropna()
  fb_likes.head()
  
  fb_likes.describe(percentiles=[.1, .25, .5, .75, .9]).astype(int)
  fb_likes.describe(percentiles=[.1,.25,.5,.75,.9])
  fb_likes.hist()
  ```

* 영화 데이터셋을 읽고 영화 제목을 인덱스로 설정하고 actor_1_facebook_likes 열에 있는 누락되지 않은 모든 값을 선택합니다. 

* describe 메서드를 사용해 분포를 추청합니다 .

* 추가적으로 히스토그램을 그려서 시각적 분포를 확인해 봅니다. 

* 그래프는 이상하기 때문에 좋아요 갯수가 2만개 보다 적은지 테스트하는 조건을 만들어 봅니다. 

  ```python
  criteria_high = fb_likes < 20000
  criteria_high.mean().round(2)
  
  fb_likes.where(criteria_high).head()
  
  fb_likes.where(criteria_high, other=20000).head()
  
  criteria_low = fb_likes > 300
  fb_likes_cap = fb_likes.where(criteria_high, other=20000)\
                         .where(criteria_low, 300)
  fb_likes_cap.head()
  
  len(fb_likes), len(fb_likes_cap)
  
  fb_likes_cap.hist()
  
  fb_likes_cap2 = fb_likes.clip(lower=300, upper=20000)
  fb_likes_cap2.equals(fb_likes_cap)
  ```

* 대략 91%의 영화에서 배우 1이 2만 개 보다 적은 적은 '좋아요'를 기록한 것을 확인할 수 있습니다. 

* where 메서드를 사용하여 불리언 조건을 입력받고, false인 부분은 모두 누락값으로 대체합니다. 

* where 메서드 두번째 매개뼌수는 other로서 어떤 값으로 대체할지 지정합니다. 

* 비슷하게 '좋아요'의 상한과 하한을 설정하는 기준을 만들 수도 있습니다. 다른 where 메서드를 체인시켜서 조건에 맞지 않는 값을 300으로 대체합니다. 

* Series의 크기는 처음과 동일합니다. 

* 수정된 Series를 이용해 히스토그램을 그려보면 데이터 범위를 보다 촘촘히 하면 더 나은 그래프를 그릴 수 있습니다. 



#### DataFrame 행 마스크 

* mask 메서드는 where 메서드와 정확히 반대되는 기능을 수행합니다. 디폴트로 불리언 조건이 참인 곳을 누락값으로 저장합니다. 

  ```python
  movie = pd.read_csv('data/movie.csv', index_col='movie_title')
  c1 = movie['title_year'] >= 2010
  c2 = movie['title_year'].isnull()
  criteria = c1 | c2
  
  movie.mask(criteria).head()
  
  movie_mask = movie.mask(criteria).dropna(how='all')
  movie_mask.head()
  
  movie_boolean = movie[movie['title_year'] < 2010]
  movie_boolean.head()
  
  movie_mask.equals(movie_boolean)
  
  movie_mask.shape == movie_boolean.shape
  
  from pandas.testing import assert_frame_equal
  assert_frame_equal(movie_boolean, movie_mask, check_dtype=False)
  
  %timeit movie.mask(criteria).dropna(how='all')
  
  %timeit movie[movie['title_year'] < 2010]
  ```

* 영화 데이터셋을 읽고, 영화 제목을 인덱스로 하고 조건을 생성합니다. 

* DataFrame의 mask 메서드를 사용하여 2010년 이후에 만들어진 영화의 모든 행을 누락값으로 만듭니다. 

* dropna 메서드를 체인시켜서 모든 값이 누락값인 행을 삭제합니다. 

* 앞에 단계에서 연산은 단순히 기본적인 불리언 인덱싱 방법을 복잡하게 구현한 것에 지나지 않기 때문에 이 두 가지 방법이 동일한 DataFrame을 생성하는지 검사합니다. 

* 이 둘이 서로 다르다고 나왔기 때문에 형태가 동일한지 살펴봅니다. 

* 앞에 mask 메서드를 사용하면서 많은 누락값을 생성했으며, 누락값은 실수 데이터 형식으로 되어있기 때문에 앞의 정수 열이 이제 실수형으로 변경되었습니다. equals 메서드는 두 열의 데이터 형식이 다르면 False를 반환하기 때문에 데이터 타입이 동일한지 확인합니다. 

* pandas에서는 이러한 경우를 대비하여 테스트 모듈 중에 개발자들이 주로 사용하는 assert_frame_equal 라는 것이 있는데 이 함수를 이용하면 데이터 형식의 동일 여부를 떠나서 검사할 수 있습니다. 

  * 이 함수는 동일하면 아무런 결과를 출력하지 않고 다를 경우에는 에러가 발생합니다. 

* 마스크 후 누락값을 삭제하는 것과 불리언 인덱싱을 하는 것 같의 속도를 비교합니다. 이경우 불리언 인덱싱이 빠르다는 사실을 알 수 있습니다. 

#### 불리언, 정수 위치, 레이블을 이용한 선택 

* 불리언은 정수도 레이블도 아니지만 이 인덱서들은 둘 다 불리언 인덱싱을 통해서도 데이터 선택이 가능합니다. 

* 이 장에서는 .iloc와 .loc 인덱서에 불리언 인덱싱을 사용해 행과 열을 필터링합니다. 

  ```python
  movie = pd.read_csv('data/movie.csv', index_col='movie_title')
  c1 = movie['content_rating'] == 'G'
  c2 = movie['imdb_score'] < 4
  criteria = c1 & c2
  
  movie_loc = movie.loc[criteria]
  movie_loc.head()
  
  movie_loc.equals(movie[criteria])
  movie_iloc = movie.iloc[criteria.values]
  movie_iloc.equals(movie_loc)
  
  movie.loc[criteria.values]
  
  criteria_col = movie.dtypes == np.int64
  criteria_col.head()
  
  movie.loc[:, criteria_col].head()
  
  movie.iloc[:, criteria_col.values].head()
  
  cols = ['content_rating', 'imdb_score', 'title_year', 'gross']
  movie.loc[criteria, cols].sort_values('imdb_score')
  
  col_index = [movie.columns.get_loc(col) for col in cols]
  col_index
  
  movie.iloc[criteria.values, col_index].sort_values('imdb_score')
  ```

* 영화 데이터 셋을 읽고 제목을 인덱스로 하고 영화 등급이 G, IMDB 점수가 4보다 낮은 모든 영화와 매칭되는 불리언 Series를 생성합니다. 

* 이 조건을 .loc 인덱서에 전달하여 행을 필터링 합니다. 

* 이 DataFrame이 인덱스 연산자에 직접 생성한 것과 동일한지 확인합니다. 

* 이제 .loc 인덱서를 사용해 동일한 불리언 인덱싱을 합니다. 

* .loc에는 인덱스 때문에 불리언 Series로 사용할 수 없기 때문에 불리언 ndarray를 사용할 수 있습니다. 배열을 추출하기 위해서 values 속성을 사용합니다. 

* 특정열을 선택하기 위해서 불리언 인덱싱을 사용할 수 있습니다. 여기서는 데이터 형식이 64비트 정수인 모든 열을 선택합니다. 

* criteria_col은 Series이기 때문에 항상 인덱스를 가지고 있습니다. 따라서 .iloc를 사용하기 위해서는 ndarray를 사용해야 합니다. 

* 불리언 Series를 사용해 행을 선택하고 동시에 정수나 레이블을 사용해 열을 선택할 수 있습니다. 행과 열을 선택하려면 그 사이에 쉼표를 써야 합니다. 행 기준을 유지하고 'content_rating', 'imdb_score', 'title_year', 'gross'을 선택합니다. 

* .loc를 사용해도 동일한 연산을 복제할 수 있지만 그러려면 모든 열의 정수 위치를 구해야 합니다. 





* 불리언 인덱싱은 .iloc와 .loc 인덱서에 모두 사용할 수 있지만, .iloc에는 Series를 전달 할 수 없고 ndarray만 전달 할 수 있다는 사실을 기억해야 합니다. 